[
  {
    "objectID": "state_dat_choropleth.html",
    "href": "state_dat_choropleth.html",
    "title": "State Data Choropleth",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mdsr)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\ncensus &lt;- read.csv(\"/Users/sirisagedahl/Downloads/NST-EST2023-ALLDATA.csv\")\n\n\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nus_states &lt;- map_data(\"state\")\ncensus_data &lt;- census |&gt; \n  filter(STATE &gt; 0) |&gt;\n  mutate(NAME = tolower(NAME))\n\nus_states |&gt;\n  full_join(census_data, join_by(\"region\" == \"NAME\")) |&gt;\n  ggplot(mapping = aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(aes(fill = BIRTHS2023), color = \"black\") + \n  labs(fill = \"Births in 2023\",\n       title = \"Births in 2023 by U.S. State\") +\n  coord_map() + \n  theme_bw() +  \n  scale_fill_gradient2() \n\n\n\n\nFrom this choropleth map displaying the number of births in 2023, we can see that California and Texas have the highest number of births. This makes sense because, in 2023, California and Texas were the top two most populous states according to the U.S. census. Therefore, the larger population, the more opportunity for giving birth."
  },
  {
    "objectID": "mini_project_1.html",
    "href": "mini_project_1.html",
    "title": "Gerrymandering in Wisconsin?",
    "section": "",
    "text": "# A tibble: 445 × 3\n# Groups:   state [56]\n   state district_id     N\n   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n 1 AK    00             12\n 2 AL    01              2\n 3 AL    02              4\n 4 AL    03              3\n 5 AL    04              2\n 6 AL    05              2\n 7 AL    06              2\n 8 AL    07              1\n 9 AR    01              2\n10 AR    02              4\n# ℹ 435 more rows\n\n\nThis table takes data from the Federal Election Commission’s 2015-2016 election cycle on the 2016 House general election results.\n\n\n# A tibble: 8 × 10\n  district     N total_votes d_votes r_votes other_votes r_prop d_prop\n     &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1        1     7      353990  107003  230072       16915  0.650  0.302\n2        2     2      397581  273537  124044           0  0.312  0.688\n3        3     2      257401  257401       0           0  0      1    \n4        4     4      285858  220181       0       65677  0      0.770\n5        5     3      390507  114477  260706       15324  0.668  0.293\n6        6     4      356935  133072  204147       19716  0.572  0.373\n7        7     4      362061  138643  223418           0  0.617  0.383\n8        8     4      363574  135682  227892           0  0.627  0.373\n# ℹ 2 more variables: other_prop &lt;dbl&gt;, winner &lt;chr&gt;\n\n\nThis table shows the districts of Wisconsin with their total votes, and divided into votes for a Democratic candidate, votes for a Republican candidate, and votes for candidates affiliated with another party. Note that some vote counts are zero due to the fact that there were no candidates of that party running in that district.\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nn\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ntotal_votes\n8\n345988.4\n49075.06\n257401\n336957\n359498\n370307.2\n397581\n\n\n\n\n\nA distribution of total votes across all 8 districts in Wisconsin\n\n\n# A tibble: 1 × 6\n      N state_votes state_d state_r d_prop r_prop\n  &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     8     2767907 1379996 1270279  0.499  0.459\n\n\nThis table shows party proportion within the whole state of Wisconsin.\n\n\n# A tibble: 8 × 5\n  district r_prop d_prop other_prop winner    \n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     \n1        5  0.668  0.293     0.0392 Republican\n2        1  0.650  0.302     0.0478 Republican\n3        8  0.627  0.373     0      Republican\n4        7  0.617  0.383     0      Republican\n5        6  0.572  0.373     0.0552 Republican\n6        2  0.312  0.688     0      Democrat  \n7        3  0      1         0      Democrat  \n8        4  0      0.770     0.230  Democrat  \n\n\nEach district ranked based on Republican proportion.\n\n\nDriver: ESRI Shapefile \nAvailable layers:\n    layer_name geometry_type features fields crs_name\n1 districts113       Polygon      436     15    NAD83\n\n\n\n\nReading layer `districts113' from data source \n  `/private/var/folders/3d/rdmztnxs0wjd_1j0j3ddjhnr0000gn/T/RtmpcJ6lEn/districts113/districtShapes' \n  using driver `ESRI Shapefile'\nSimple feature collection with 436 features and 15 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1473 ymin: 18.91383 xmax: 179.7785 ymax: 71.35256\nGeodetic CRS:  NAD83\n\n\n\n\n[1] \"sf\"         \"data.frame\"\n\n\n\n\n\n\n\nNote the shapes of the 8 Wisconsin districts.\n\n\nSimple feature collection with 6 features and 25 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -92.808 ymin: 42.49198 xmax: -87.50719 ymax: 45.20957\nGeodetic CRS:  WGS 84\n  STATENAME           ID DISTRICT STARTCONG ENDCONG DISTRICTSI COUNTY PAGE  LAW\n1 Wisconsin 055113114001        1       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n2 Wisconsin 055113114002        2       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n3 Wisconsin 055113114003        3       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n4 Wisconsin 055113114004        4       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n5 Wisconsin 055113114005        5       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n6 Wisconsin 055113114006        6       113     114       &lt;NA&gt;   &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n  NOTE BESTDEC                  FINALNOTE RNOTE                 LASTCHANGE\n1 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n2 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n3 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n4 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n5 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n6 &lt;NA&gt;    &lt;NA&gt; {\"From US Census website\"}  &lt;NA&gt; 2016-05-29 16:44:10.857626\n  FROMCOUNTY state N total_votes d_votes r_votes other_votes    r_prop\n1          F    WI 7      353990  107003  230072       16915 0.6499393\n2          F    WI 2      397581  273537  124044           0 0.3119968\n3          F    WI 2      257401  257401       0           0 0.0000000\n4          F    WI 4      285858  220181       0       65677 0.0000000\n5          F    WI 3      390507  114477  260706       15324 0.6676090\n6          F    WI 4      356935  133072  204147       19716 0.5719445\n     d_prop other_prop     winner                       geometry\n1 0.3022769 0.04778384 Republican MULTIPOLYGON (((-89.08072 4...\n2 0.6880032 0.00000000   Democrat MULTIPOLYGON (((-90.43 43.1...\n3 1.0000000 0.00000000   Democrat MULTIPOLYGON (((-91.3984 44...\n4 0.7702461 0.22975393   Democrat MULTIPOLYGON (((-88.06601 4...\n5 0.2931497 0.03924129 Republican MULTIPOLYGON (((-89.01359 4...\n6 0.3728186 0.05523695 Republican MULTIPOLYGON (((-89.78555 4...\n\n\n\nlibrary(ggspatial)\nwi &lt;- ggplot(data = wi_merged, aes(fill = winner)) +\n  annotation_map_tile(zoom = 6, type = \"osm\", progress = \"none\") + \n  geom_sf(alpha = 0.5) +\n  scale_fill_manual(\"Winner\", values = c(\"blue\", \"red\")) + \n  geom_sf_label(aes(label = DISTRICT), fill = \"white\") + \n  theme_void()\nwi\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\nLoading required namespace: raster\n\n\n\n\n\nThis visualization shows the 8 Wisconsin districts along with the party affiliated with the winning candidate.\n\nwi +\n  aes(fill = r_prop) + \n  scale_fill_distiller(\n    \"Proportion\\nRepublican\", \n    palette = \"RdBu\", \n    limits = c(0, 1)\n  )\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\nThis visualization is very similar to the previous, but with color opacity representing the size of proportion of the winning party. In other words, the colors are darker when the proprtion of that party is higher.\n\nlibrary(leaflet)\npal &lt;- colorNumeric(palette = \"RdBu\", domain = c(0, 1))\n\nleaflet_wi &lt;- leaflet(wi_merged) |&gt;\n  addTiles() |&gt;\n  addPolygons(\n    weight = 1, fillOpacity = 0.7, \n    color = ~pal(1 - r_prop),  \n    popup = ~paste(\"District\", DISTRICT, \"&lt;/br&gt;\", round(r_prop, 4))\n  ) |&gt;                         \n  setView(lng = -90, lat = 45, zoom = 6)\nleaflet_wi\n\n\n\n\n\nThis leaflet plot takes a look at relative proportion of votes per district without the district number labels. Additionally, this plot is interactive, allowing you to zoom in and out of the map, assessing shape and proportion attached to each district.\nFrom this data visualization, we can’t confirm or deny gerrymandering within the state of Wisconsin. There are some oddly shaped districts that are reportedly 100% Democratic (due to a Democratic candidate being the only party running). In order to confirm gerrymandering, we would need to further analyze proportions of parties within districts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Siri Sagedahl",
    "section": "",
    "text": "Math, Statistics & Data Science Student  at St. Olaf College\n\n\nBA in Math with Statistics & Data Science concentration 2026 | St. Olaf College"
  },
  {
    "objectID": "index.html#siri-sagedahl",
    "href": "index.html#siri-sagedahl",
    "title": "Siri Sagedahl",
    "section": "",
    "text": "Math, Statistics & Data Science Student  at St. Olaf College\n\n\nBA in Math with Statistics & Data Science concentration 2026 | St. Olaf College"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "R_tip_of_the_day.html",
    "href": "R_tip_of_the_day.html",
    "title": "R Tip of the Day",
    "section": "",
    "text": "library(tidyverse)\n\n\nggplot(faithful, aes(x = eruptions, y = waiting)) +\n geom_point() +\n  labs(x = \"Duration of Eruption (Min.)\", y = \"Waiting Time to Next Eruption (Min.)\", title = \"Scatterplot of Old Faithful Eruption Data\") +\n xlim(0.5, 6) +\n ylim(40, 110)\n\n\n\n\n\nggplot(faithful, aes(x = eruptions, y = waiting)) +\n geom_point() +\n  labs(x = \"Duration of Eruption (Min.)\", y = \"Waiting Time to Next Eruption (Min.)\", title = \"Scatterplot with Contours of Old Faithful Eruption Data\") +\n xlim(0.5, 6) +\n ylim(40, 110) +\n  geom_density_2d()\n\n\n\n\n\nggplot(faithful, aes(x = eruptions, y = waiting)) +\n geom_point() +\n  labs(x = \"Duration of Eruption (Min.)\", y = \"Waiting Time to Next Eruption (Min.)\", title = \"Filled Contour Map of Old Faithful Eruption Data\") +\n xlim(0.5, 6) +\n ylim(40, 110) +\n  geom_density_2d_filled(alpha = 0.5)\n\n\n\n\n\nggplot(faithful, aes(x = eruptions, y = waiting)) +\n geom_point() +\n  labs(x = \"Duration of Eruption (Min.)\", y = \"Waiting Time to Next Eruption (Min.)\", title = \"Filled Contour Map of Old Faithful Eruption Data w/ Lines\") +\n xlim(0.5, 6) +\n ylim(40, 110) +\n  geom_density_2d_filled(alpha = 0.5) +\n  geom_density_2d(linewidth = 0.25, color = \"black\")\n\n\n\n\n\nset.seed(4393)\ndsmall &lt;- diamonds[sample(nrow(diamonds), 1000), ]\ndsmall |&gt;\n  ggplot(aes(x, y)) +\n  geom_density_2d(aes(colour = cut)) +\n  labs(x = \"Length (mm)\", y = \"Width (mm)\", title = \"Size of Diamond by Cut\")\n\n\n\n\n\ndsmall |&gt;\n  ggplot(aes(x, y)) +\n  geom_density_2d_filled() +\n  facet_wrap(vars(cut)) +\n  labs(x = \"Length (mm)\", y = \"Width (mm)\", title = \"Size of Diamond by Cut\")\n\n\n\n\n\ndsmall |&gt;\n  ggplot(aes(x, y)) +\n  geom_density_2d_filled(contour_var = \"ndensity\") + facet_wrap(vars(cut)) +\n  labs(x = \"Length (mm)\", y = \"Width (mm)\", title = \"Size of Diamond by Cut (intensity standardized)\")\n\n\n\n\n\ndsmall |&gt;\n  ggplot(aes(x, y)) +\n  stat_density_2d(geom = \"raster\",\n                  aes(fill = after_stat(density)),\n                  contour = FALSE) +\n  scale_fill_viridis_c() +\n  labs(x = \"Length (mm)\", y = \"Width (mm)\", title = \"Size of Diamond by Cut\")\n\n\n\n\n\ndsmall |&gt;\n  ggplot(aes(x, y)) +\n  stat_density_2d(geom = \"point\", \n                  aes(size = after_stat(density)),\n                  n = 20,\n                  contour = FALSE) +\n  labs(x = \"Length (mm)\", y = \"Width (mm)\", title = \"Size of Diamond by Cut\")"
  },
  {
    "objectID": "mini_project2.html",
    "href": "mini_project2.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "This project is meant to show how the null hypothesis and sample size affects the power of a particular study into the prevalence of a bio-marker called PARP. Below is an email asking for guidance on the number of participants to have in a certain study:\n\nDo you mind if I ask for some statistical guidance? This is probably a pretty straightforward question but I’m struggling with it a bit.\n\n\nOne of our docs wants to conduct a study looking at a biomarker called PARP. The hypothesis is that expression of PARP is correlated with decreased survival in breast cancer. The test will be done on archived tissue and will be read as either positive or negative. The hypothesis is that patients who overexpress PARP will have a response rate to chemotherapy of 10% and that non-expressers will have a response rate of 25%.\n\n\nThe proposed patient population is 220 patients. This is the power analysis:\n\n\nSample Size for Response Rate (2-sample comparison, 1-sided, alpha=0.05)\n\n\nPower = 80\n\n\nNull Hypothesis (H0) = .05 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 35\n\n\nSample Size per Group (nQuery) = 39\n\n\nPower = 85\n\n\nNull Hypothesis (H0) = .05 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 41\n\n\nSample Size per Group (nQuery) = 45\n\n\nPower = 80\n\n\nNull Hypothesis (H0) = .10 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 76\n\n\nSample Size per Group (nQuery) = 79\n\n\netc. (Many more runs of their power software with different levels of power and different assumptions about HO and H1)\n\n\nNow the unknown variable is what proportion of tumors will express PARP. From looking at this it appears that he is assuming that the sample size will be equal in each group but in fact, it appears that PARP expression may be present in 80-90% of tumors. Let’s assume that 80% of tumors are expressers and 20% are non-expressers. I’m not crazy in assuming that will have a significant impact on our needed study size to show a p value of 0.05 at 80% power with the above assumptions, am I?"
  },
  {
    "objectID": "mini_project2.html#project-description",
    "href": "mini_project2.html#project-description",
    "title": "Mini Project 2",
    "section": "",
    "text": "This project is meant to show how the null hypothesis and sample size affects the power of a particular study into the prevalence of a bio-marker called PARP. Below is an email asking for guidance on the number of participants to have in a certain study:\n\nDo you mind if I ask for some statistical guidance? This is probably a pretty straightforward question but I’m struggling with it a bit.\n\n\nOne of our docs wants to conduct a study looking at a biomarker called PARP. The hypothesis is that expression of PARP is correlated with decreased survival in breast cancer. The test will be done on archived tissue and will be read as either positive or negative. The hypothesis is that patients who overexpress PARP will have a response rate to chemotherapy of 10% and that non-expressers will have a response rate of 25%.\n\n\nThe proposed patient population is 220 patients. This is the power analysis:\n\n\nSample Size for Response Rate (2-sample comparison, 1-sided, alpha=0.05)\n\n\nPower = 80\n\n\nNull Hypothesis (H0) = .05 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 35\n\n\nSample Size per Group (nQuery) = 39\n\n\nPower = 85\n\n\nNull Hypothesis (H0) = .05 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 41\n\n\nSample Size per Group (nQuery) = 45\n\n\nPower = 80\n\n\nNull Hypothesis (H0) = .10 (Response Rate for Overexpression Group)\n\n\nAlternative Hypothesis (H1) = .25 (Response Rate for Normal Expression Group)\n\n\nSample Size per Group (STPlan) = 76\n\n\nSample Size per Group (nQuery) = 79\n\n\netc. (Many more runs of their power software with different levels of power and different assumptions about HO and H1)\n\n\nNow the unknown variable is what proportion of tumors will express PARP. From looking at this it appears that he is assuming that the sample size will be equal in each group but in fact, it appears that PARP expression may be present in 80-90% of tumors. Let’s assume that 80% of tumors are expressers and 20% are non-expressers. I’m not crazy in assuming that will have a significant impact on our needed study size to show a p value of 0.05 at 80% power with the above assumptions, am I?"
  },
  {
    "objectID": "mini_project2.html#interpretation",
    "href": "mini_project2.html#interpretation",
    "title": "Mini Project 2",
    "section": "Interpretation:",
    "text": "Interpretation:\nThis graph shows the impact of the null hypothesis, in this case being the assumed prevalence of of PARP bio-marker expression in tumors, and the sample size on the study’s relative power. If we assume the bio-marker prevalence to be 0.2, we need a sample size of about 370 to achieve 80% power. If we assume the prevalence to be 0.4 or 0.6, the sample size per group must be around 225, and a prevalence of 0.8 must have a sample size around 310 to achieve 80% power. Thus, to answer the physician’s question, the assumed proportion of PARP-expressing tumors has a significant impact on the needed sample size in order to maintain power."
  },
  {
    "objectID": "mini_project2.html#code",
    "href": "mini_project2.html#code",
    "title": "Mini Project 2",
    "section": "Code",
    "text": "Code\n\npower_analysis &lt;- function(n_per_group, prevalence, true_response_expressors, true_response_nonexpressors, alpha = 0.05) {\n  n_expressors &lt;- round(n_per_group * prevalence)\n  n_nonexpressors &lt;- n_per_group - n_expressors\n  responders_expressors &lt;- rbinom(1, size = n_expressors, prob = true_response_expressors)\n  responders_nonexpressors &lt;- rbinom(1, size = n_nonexpressors, prob = true_response_nonexpressors)\n  \n  observed_table &lt;- matrix(c(responders_expressors, responders_nonexpressors,\n                              n_expressors - responders_expressors, n_nonexpressors - responders_nonexpressors), nrow = 2, byrow = TRUE)\n  chisq_stat &lt;- chisq.test(observed_table, correct = TRUE)$statistic\n  p_value &lt;- 1 - pchisq(chisq_stat, df = 1)\n  \n  power &lt;- ifelse(p_value &lt; alpha, 1, 0)\n  return(power)\n}\n\nalpha &lt;- 0.05\ndesired_power &lt;- 0.8\nprevalence_options &lt;- c(0.2, 0.4, 0.6, 0.8)\ntrue_response_expressors &lt;- 0.1\ntrue_response_nonexpressors &lt;- 0.25\nmin_sample_size &lt;- 100\n\n\npower_curves &lt;- list()\n\nfor (prevalence in prevalence_options) {\n  sample_sizes &lt;- seq(from = min_sample_size, to = 500, by = 20)\n  power_values &lt;- vector(\"double\", length = length(sample_sizes))\n  \n  for (i in 1:length(sample_sizes)) {\n    sample_size &lt;- sample_sizes[i]\n    power &lt;- 0\n    \n    num_sims &lt;- 1000\n    for (j in 1:num_sims) {\n      power &lt;- power + power_analysis(sample_size, prevalence, true_response_expressors, true_response_nonexpressors, alpha)\n    }\n    power_values[i] &lt;- power / num_sims\n  }\n  list_num &lt;- round(prevalence / .2)\n  power_curves[[list_num]] &lt;- data.frame(sample_size = sample_sizes, power = power_values, prevalence = prevalence)\n}\n\n\nall_power_curves &lt;- do.call(rbind, power_curves)\n\nall_power_curves |&gt;\n  ggplot(aes(x = sample_size, y = power, color = factor(prevalence))) +\n  geom_line(linewidth = 0.7) +\n  labs(title = \"Power Curves for Different Prevalence Levels (Chi-Square Test)\",\n       x = \"Sample Size per Group\",\n       y = \"Power\",\n       color = \"Prevalence\") +\n  geom_hline(yintercept = desired_power, linetype = \"dashed\", color = \"red\") +\n  theme_bw()"
  }
]